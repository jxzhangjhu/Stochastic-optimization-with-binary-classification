{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.08298921585083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-41:\n",
      "Process ForkPoolWorker-47:\n",
      "Process ForkPoolWorker-48:\n",
      "Process ForkPoolWorker-46:\n",
      "Process ForkPoolWorker-45:\n",
      "Process ForkPoolWorker-44:\n",
      "Process ForkPoolWorker-43:\n",
      "Process ForkPoolWorker-42:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
      "    with self._rlock:\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
      "    task = get()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/synchronize.py\", line 96, in __enter__\n",
      "    return self._semlock.__enter__()\n",
      "KeyboardInterrupt\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/Users/7jz/anaconda3/lib/python3.6/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "from math import*\n",
    "import __main__\n",
    "global PI\n",
    "import os\n",
    "import time\n",
    "PI=float(acos(-1))\n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "\n",
    "random.seed(123)\n",
    "\n",
    "data_size = 10000;\n",
    "\n",
    "arr = np.random.randint(1, 10, size=[data_size, 8])\n",
    "data_input = arr.tolist()\n",
    "datasets = data_input\n",
    "\n",
    "def ssh(num):\n",
    "#     global datasets\n",
    "#     arr = np.random.randint(1, 10, size=[data_size, 8])\n",
    "#     datasets = arr.tolist()\n",
    "    ply_angle = datasets[num]\n",
    "    \n",
    "    bas_ply=[-60, -45, -30, -15, 0, 15, 30, 45, 60, 90]\n",
    "\n",
    "    AA1=bas_ply[ply_angle[0]]\n",
    "    AA2=bas_ply[ply_angle[1]]\n",
    "    AA3=bas_ply[ply_angle[2]]\n",
    "    AA4=bas_ply[ply_angle[3]]\n",
    "    AA5=bas_ply[ply_angle[4]]\n",
    "    AA6=bas_ply[ply_angle[5]]\n",
    "    AA7=bas_ply[ply_angle[6]]\n",
    "    AA8=bas_ply[ply_angle[7]]\n",
    "\n",
    "    ### ply stacking sequence###\n",
    "    AAA=[AA1/180.0*PI,AA2/180.0*PI,AA3/180.0*PI,AA4/180.0*PI,AA5/180.0*PI,AA6/180.0*PI,AA7/180.0*PI,AA8/180.0*PI,AA8/180.0*PI,AA7/180.0*PI,AA6/180.0*PI,AA5/180.0*PI,AA4/180.0*PI,AA3/180.0*PI,AA2/180.0*PI,AA1/180.0*PI]\n",
    "    pi=3.14159265358979\n",
    "\n",
    "    R=250.0   ##  radius##\n",
    "    H=510.0   ##  Height##\n",
    "    td=0.125  #layer thickness##\n",
    "\n",
    "    TTT=[-td*8,-td*7,-td*6,-td*5,-td*4,-td*3,-td*2,-td*1,td*0,td*1,td*2,td*3,td*4,td*5,td*6,td*7,td*8]\n",
    "\n",
    "    ###material property###\n",
    "\n",
    "    E1=123550.0  \n",
    "    E2=8707.9\n",
    "    G12=5695.0\n",
    "    miu12=0.31946\n",
    "\n",
    "    miu21=miu12*E2/E1\n",
    "    Q11=E1/(1-miu12*miu21)\n",
    "    Q12=miu21*E1/(1-miu12*miu21)\n",
    "    Q22=E2/(1-miu12*miu21)\n",
    "    Q66=G12\n",
    "\n",
    "    A11=0.0\n",
    "    A12=0.0\n",
    "    A22=0.0\n",
    "    A66=0.0\n",
    "\n",
    "    D11=0.0\n",
    "    D12=0.0\n",
    "    D22=0.0\n",
    "    D66=0.0\n",
    "\n",
    "    for i in range(0,16):\n",
    "        A11=A11+(Q11*cos(AAA[i])**4+2*(Q12+2*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q22*sin(AAA[i])**4)*(TTT[i+1]-TTT[i])\n",
    "        A12=A12+((Q11+Q22-4*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q12*(sin(AAA[i])**4+cos(AAA[i])**4))*(TTT[i+1]-TTT[i])\n",
    "        A22=A22+(Q11*sin(AAA[i])**4+2*(Q12+2*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q22*cos(AAA[i])**4)*(TTT[i+1]-TTT[i])\n",
    "        A66=A66+((Q11+Q22-2*Q12-2*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q66*(sin(AAA[i])**4+cos(AAA[i])**4))*(TTT[i+1]-TTT[i])\n",
    "        D11=D11+(Q11*cos(AAA[i])**4+2*(Q12+2*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q22*sin(AAA[i])**4)*(TTT[i+1]**3-TTT[i]**3)/3.0\n",
    "        D12=D12+((Q11+Q22-4*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q12*(sin(AAA[i])**4+cos(AAA[i])**4))*(TTT[i+1]**3-TTT[i]**3)/3.0\n",
    "        D22=D22+(Q11*sin(AAA[i])**4+2*(Q12+2*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q22*cos(AAA[i])**4)*(TTT[i+1]**3-TTT[i]**3)/3.0\n",
    "        D66=D66+((Q11+Q22-2*Q12-2*Q66)*sin(AAA[i])**2*cos(AAA[i])**2+Q66*(sin(AAA[i])**4+cos(AAA[i])**4))*(TTT[i+1]**3-TTT[i]**3)/3.0\n",
    "\n",
    "    #####bianliang########\n",
    "\n",
    "    D= 2*R\n",
    "    L= H\n",
    "\n",
    "    #xian\n",
    "    a=[[A11,A12,0],[A12,A22,0],[0,0,A66]]\n",
    "    b=[[0,0,0],[0,0,0],[0,0,0]]\n",
    "    d=[[D11,D12,0],[D12,D22,0],[0,0,D66]]\n",
    "\n",
    "    alpha=PI/L\n",
    "    beta=2/D\n",
    "\n",
    "    mm=50\n",
    "    nn=50\n",
    "    kmm=0\n",
    "    knn=0\n",
    "    kmm11=0\n",
    "    knn11=0\n",
    "    F=[[0 for col in range(nn)] for row in range(mm)]\n",
    "    Fcr=1e16\n",
    "\n",
    "    for m in range(1,mm+1):\n",
    "        for n in range(1,nn+1):\n",
    "            xi11=2*a[0][0]*(m*alpha)**2+2*a[2][2]*(n*beta)**2\n",
    "            xi12=2*(a[0][1]+a[2][2])*m*alpha*n*beta\n",
    "            xi13=4*a[0][1]*m*alpha/D-2*b[0][0]*(m*alpha)**3-2*(b[0][1]+2*b[2][2])*m*alpha*(n*beta)**2\n",
    "            xi22=2*a[1][1]*(n*beta)**2+2*a[2][2]*(m*alpha)**2\n",
    "            xi23=4*a[1][1]*n*beta/D-2*b[1][1]*(n*beta)**3-2*(b[0][1]+2*b[2][2])*(m*alpha)**2*n*beta\n",
    "            xi33=4*(d[0][1]+2*d[2][2])*(m*alpha*n*beta)**2+8*a[1][1]/(D**2)\\\n",
    "            +2*d[0][0]*(m*alpha)**4+2*d[1][1]*(n*beta)**4-8*(b[1][1]*(n*beta)**2+b[0][1]*(m*alpha)**2)/D\n",
    "            xi21=xi12\n",
    "            xi31=xi13\n",
    "            xi32=xi23\n",
    "            det1=xi11*(xi22*xi33-xi32*xi23)-xi12*(xi21*xi33-xi31*xi23)+xi13*(xi21*xi32-xi31*xi22)\n",
    "            det2=xi11*xi22-xi21*xi12\n",
    "            Nx=det1/det2/(2*((m*alpha)**2))\n",
    "            F[m-1][n-1]=Nx*PI*D\n",
    "            if Fcr>F[m-1][n-1]:\n",
    "              Fcr=F[m-1][n-1]\n",
    "              kmm=m\n",
    "              knn=2*n\n",
    "\n",
    "    for m in range(1,mm+1):\n",
    "        xi11=2*a[0][0]*(m*alpha)**2\n",
    "        xi12=0\n",
    "        xi13=4*a[0][1]*m*alpha/D-2*b[0][0]*(m*alpha)**3\n",
    "        xi22=2*a[2][2]*(m*alpha)**2\n",
    "        xi23=0\n",
    "        xi33=8*a[1][1]/(D**2)+2*d[0][0]*(m*alpha)**4-8*b[0][1]*(m*alpha)**2/D\n",
    "        xi21=xi12\n",
    "        xi31=xi13\n",
    "        xi32=xi23\n",
    "        det1=xi11*(xi22*xi33-xi32*xi23)-xi12*(xi21*xi33-xi31*xi23)+xi13*(xi21*xi32-xi31*xi22)\n",
    "        det2=xi11*xi22-xi21*xi12\n",
    "        Nx=det1/det2/(2*((m*alpha)**2))\n",
    "        Fn1=Nx*PI*D\n",
    "        if Fcr>Fn1:\n",
    "          Fcr=Fn1\n",
    "          kmm=m\n",
    "          knn=1\n",
    "\n",
    "    return Fcr\n",
    "\n",
    "\n",
    "# map async parallel \n",
    "# pool = mp.Pool(mp.cpu_count())\n",
    "pool = mp.Pool(processes = 8)\n",
    "\n",
    "start = time.time()\n",
    "results_map = pool.map(ssh, range(data_size))\n",
    "end = time.time() \n",
    "print(end - start) #0.0037827491760253906\n",
    "# print(results_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "598326.738679199\n",
      "torch.Size([10000, 8])\n",
      "torch.Size([10000, 1])\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "results_map_sort = sorted(results_map) # note that sorted change the sort but didn't change the original one\n",
    "# print(results_map_sort)\n",
    "median_value = results_map_sort[data_size//2]\n",
    "print(median_value)\n",
    "\n",
    "results_map_new = np.zeros((data_size,1))\n",
    "# print(type(results_map))\n",
    "output_scikit = np.zeros(data_size)\n",
    "\n",
    "for i in range(data_size):\n",
    "    if results_map[i] > median_value:\n",
    "        results_map_new[i,:] = 1\n",
    "        output_scikit[i] = 1\n",
    "    else:\n",
    "        results_map_new[i,:] = 0\n",
    "        output_scikit[i] = 0\n",
    "        \n",
    "# print(results_map) # new results_map transfer to [0,1]\n",
    "# print(datasets)\n",
    "# type(datasets)\n",
    "# type(results_map)\n",
    "\n",
    "X = torch.FloatTensor(datasets)\n",
    "Y = torch.FloatTensor(results_map_new)\n",
    "# type(data_tensor)\n",
    "#type(output_tensor)\n",
    "print(X.size())\n",
    "print(Y.size())\n",
    "# print(X)\n",
    "# print(Y)\n",
    "\n",
    "\n",
    "print(type(datasets))\n",
    "print(type(output_scikit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training by classification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import svm\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# clf = svm.SVC(gamma=0.001,probability=True)\n",
    "# X = datasets\n",
    "# y = results_map\n",
    "\n",
    "# clf.fit(X, y) \n",
    "\n",
    "# score_svm = cross_val_score(clf, X, y, scoring='recall_macro',cv=5)  \n",
    "# print(score_svm)\n",
    "\n",
    "# clf.predict([datasets[3]])\n",
    "# clf.predict_proba([datasets[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.70750428\n",
      "Iteration 2, loss = 0.68525905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1.]\n",
      "4\n",
      "2\n",
      "0.68525905140777\n",
      "logistic\n",
      "1\n",
      "Iteration 1, loss = 0.71105447\n",
      "Iteration 2, loss = 0.69025022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 3, loss = 0.67906655\n",
      "Iteration 4, loss = 0.67102537Iteration 1, loss = 0.71058414\n",
      "Iteration 2, loss = 0.68956694\n",
      "Iteration 3, loss = 0.67839425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.67026259\n",
      "Iteration 1, loss = 0.71054707\n",
      "Iteration 2, loss = 0.68999699\n",
      "Iteration 3, loss = 0.67908270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.71040751\n",
      "Iteration 2, loss = 0.69001552\n",
      "Iteration 3, loss = 0.67922617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/sklearn/neural_network/multilayer_perceptron.py:566: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 4, loss = 0.67153231\n",
      "Iteration 1, loss = 0.70987896\n",
      "Iteration 2, loss = 0.68891258\n",
      "Iteration 3, loss = 0.67772354\n",
      "Iteration 4, loss = 0.66797868\n",
      "Iteration 5, loss = 0.66076309\n",
      "Iteration 6, loss = 0.65432497\n",
      "Iteration 7, loss = 0.64836822\n",
      "Iteration 8, loss = 0.64320504\n",
      "Iteration 9, loss = 0.63835642\n",
      "Iteration 10, loss = 0.63460358\n",
      "Iteration 11, loss = 0.63077928\n",
      "Iteration 12, loss = 0.62718790\n",
      "Iteration 13, loss = 0.62381456\n",
      "Iteration 14, loss = 0.62077123\n",
      "Iteration 15, loss = 0.61761712\n",
      "Iteration 16, loss = 0.61554307\n",
      "Iteration 17, loss = 0.61356642\n",
      "Iteration 18, loss = 0.61179003\n",
      "Iteration 19, loss = 0.60989857\n",
      "Iteration 20, loss = 0.60835301\n",
      "Iteration 21, loss = 0.60761748\n",
      "Iteration 22, loss = 0.60610221\n",
      "Iteration 23, loss = 0.60471352\n",
      "Iteration 24, loss = 0.60338649\n",
      "Iteration 25, loss = 0.60247688\n",
      "Iteration 26, loss = 0.60120829\n",
      "Iteration 27, loss = 0.60008965\n",
      "Iteration 28, loss = 0.59934287\n",
      "Iteration 29, loss = 0.59812438\n",
      "Iteration 30, loss = 0.59718856\n",
      "Iteration 31, loss = 0.59635522\n",
      "Iteration 32, loss = 0.59539137\n",
      "Iteration 33, loss = 0.59459703\n",
      "Iteration 34, loss = 0.59373036\n",
      "Iteration 35, loss = 0.59269562\n",
      "Iteration 36, loss = 0.59208668\n",
      "Iteration 37, loss = 0.59118603\n",
      "Iteration 38, loss = 0.59034438\n",
      "Iteration 39, loss = 0.58932945\n",
      "Iteration 40, loss = 0.58913068\n",
      "Iteration 41, loss = 0.58773001\n",
      "Iteration 42, loss = 0.58685702\n",
      "Iteration 43, loss = 0.58637343\n",
      "Iteration 44, loss = 0.58531421\n",
      "Iteration 45, loss = 0.58458694\n",
      "Iteration 46, loss = 0.58379583\n",
      "Iteration 47, loss = 0.58319858\n",
      "Iteration 48, loss = 0.58197791\n",
      "Iteration 49, loss = 0.58113258\n",
      "Iteration 50, loss = 0.58042468\n",
      "Iteration 51, loss = 0.57965132\n",
      "Iteration 52, loss = 0.57869802\n",
      "Iteration 53, loss = 0.57789705\n",
      "Iteration 54, loss = 0.57768178\n",
      "Iteration 55, loss = 0.57634705\n",
      "Iteration 56, loss = 0.57578952\n",
      "Iteration 57, loss = 0.57481211\n",
      "Iteration 58, loss = 0.57462681\n",
      "Iteration 59, loss = 0.57316506\n",
      "Iteration 60, loss = 0.57240683\n",
      "Iteration 61, loss = 0.57233358\n",
      "Iteration 62, loss = 0.57134586\n",
      "Iteration 63, loss = 0.57065593\n",
      "Iteration 64, loss = 0.56987642\n",
      "Iteration 65, loss = 0.56896779\n",
      "Iteration 66, loss = 0.56811607\n",
      "Iteration 67, loss = 0.56714080\n",
      "Iteration 68, loss = 0.56646544\n",
      "Iteration 69, loss = 0.56605671\n",
      "Iteration 70, loss = 0.56516253\n",
      "Iteration 71, loss = 0.56483268\n",
      "Iteration 72, loss = 0.56398724\n",
      "Iteration 73, loss = 0.56332496\n",
      "Iteration 74, loss = 0.56251818\n",
      "Iteration 75, loss = 0.56196378\n",
      "Iteration 76, loss = 0.56116635\n",
      "Iteration 77, loss = 0.56064004\n",
      "Iteration 78, loss = 0.55973167\n",
      "Iteration 79, loss = 0.55987270\n",
      "Iteration 80, loss = 0.55870002\n",
      "Iteration 81, loss = 0.55788760\n",
      "Iteration 82, loss = 0.55710464\n",
      "Iteration 83, loss = 0.55703842\n",
      "Iteration 84, loss = 0.55609306\n",
      "Iteration 85, loss = 0.55581587\n",
      "Iteration 86, loss = 0.55499728\n",
      "Iteration 87, loss = 0.55432435\n",
      "Iteration 88, loss = 0.55328852\n",
      "Iteration 89, loss = 0.55274458\n",
      "Iteration 90, loss = 0.55202661\n",
      "Iteration 91, loss = 0.55189421\n",
      "Iteration 92, loss = 0.55085683\n",
      "Iteration 93, loss = 0.54980320\n",
      "Iteration 94, loss = 0.55046689\n",
      "Iteration 95, loss = 0.54975509\n",
      "Iteration 96, loss = 0.54994458\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000200\n",
      "Iteration 97, loss = 0.54873714\n",
      "Iteration 98, loss = 0.54837407\n",
      "Iteration 99, loss = 0.54814958\n",
      "Iteration 100, loss = 0.54789563\n",
      "Iteration 101, loss = 0.54777936\n",
      "Iteration 102, loss = 0.54751900\n",
      "Iteration 103, loss = 0.54733051\n",
      "Iteration 104, loss = 0.54708347\n",
      "Iteration 105, loss = 0.54689337\n",
      "Iteration 106, loss = 0.54669235\n",
      "Iteration 107, loss = 0.54660498\n",
      "Iteration 108, loss = 0.54657930\n",
      "Iteration 109, loss = 0.54646014\n",
      "Iteration 110, loss = 0.54636508\n",
      "Iteration 111, loss = 0.54615415\n",
      "Iteration 112, loss = 0.54583352\n",
      "Iteration 113, loss = 0.54569373\n",
      "Iteration 114, loss = 0.54583564\n",
      "Iteration 115, loss = 0.54542559\n",
      "Iteration 116, loss = 0.54523761\n",
      "Iteration 117, loss = 0.54516084\n",
      "Iteration 118, loss = 0.54505021\n",
      "Iteration 119, loss = 0.54501628\n",
      "Iteration 120, loss = 0.54501067\n",
      "Iteration 121, loss = 0.54496936\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000040\n",
      "Iteration 122, loss = 0.54510164\n",
      "Iteration 123, loss = 0.54507553\n",
      "Iteration 124, loss = 0.54499272\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000008\n",
      "Iteration 125, loss = 0.54493457\n",
      "Iteration 126, loss = 0.54490857\n",
      "Iteration 127, loss = 0.54488293\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000002\n",
      "Iteration 128, loss = 0.54485850\n",
      "Iteration 129, loss = 0.54485349\n",
      "Iteration 130, loss = 0.54485141\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Setting learning rate to 0.000000\n",
      "Iteration 131, loss = 0.54485044\n",
      "Iteration 132, loss = 0.54484984\n",
      "Iteration 133, loss = 0.54484871\n",
      "Training loss did not improve more than tol=0.000100 for two consecutive epochs. Learning rate too small. Stopping.\n",
      "[0.72461556 0.727      0.72485    0.727      0.72298803]\n"
     ]
    }
   ],
   "source": [
    "# scikit-learn MLP training \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# preprocessing data \n",
    "\n",
    "X_scale = preprocessing.scale(datasets)\n",
    "# print(X_scale)\n",
    "\n",
    "# sgd optimizer \n",
    "mlp = MLPClassifier(solver='sgd', activation='relu',alpha=1e-4, hidden_layer_sizes=(100,100),\n",
    "                    learning_rate='adaptive', random_state=1, max_iter=500,verbose=True)\n",
    "\n",
    "# lbfgs - very slow \n",
    "# mlp = MLPClassifier(solver='lbfgs', activation='relu',alpha=1e-4,hidden_layer_sizes=(100,100),\n",
    "#                     random_state=1,max_iter=50,verbose=10,learning_rate_init=.1)\n",
    "\n",
    "# adam \n",
    "# mlp = MLPClassifier(solver='adam', activation='relu',alpha=1e-4,hidden_layer_sizes=(100,100),\n",
    "#                     random_state=1,max_iter=50,verbose=10,learning_rate_init=.1)\n",
    "\n",
    "mlp.fit(X_scale, output_scikit) \n",
    "print(mlp.classes_)\n",
    "print(mlp.n_layers_)\n",
    "print(mlp.n_iter_)\n",
    "print(mlp.loss_)\n",
    "print(mlp.out_activation_)\n",
    "print(mlp.n_outputs_)\n",
    "\n",
    "score_mlp = cross_val_score(mlp, X_scale, output_scikit, scoring='recall_macro',cv=5)  \n",
    "print(score_svm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a2c42bb00>]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# pytorch binary classification \n",
    "\n",
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, 8)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.dout = nn.Dropout(0.2) # previous one is 0.2 \n",
    "        \n",
    "        self.fc2 = nn.Linear(8, 64) # can be adjusted \n",
    "#         self.prelu = nn.PReLU(1)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.out_act = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, input_):\n",
    "        \n",
    "        a1 = self.fc1(input_)\n",
    "        h1 = self.relu1(a1)\n",
    "        \n",
    "        dout = self.dout(h1)\n",
    "#         a2 = self.fc2(h1)\n",
    "        a2 = self.fc2(dout)\n",
    "#         h2 = self.prelu(a2)\n",
    "        h2 = self.relu2(a2)\n",
    "        \n",
    "        a3 = self.out(h2)\n",
    "        y = self.out_act(a3)\n",
    "        return y\n",
    "    \n",
    "net = Net()\n",
    "# opt = optim.Adam(net.parameters(), lr=0.001, betas=(0.9, 0.999)) # turing the learn rate? \n",
    "opt = optim.RMSprop(net.parameters(), lr=0.001) # turing the learn rate? \n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "def train_epoch(model, opt, criterion, batch_size=50): # batch_size = 50\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for beg_i in range(0, X.size(0), batch_size):\n",
    "        x_batch = X[beg_i:beg_i + batch_size, :]\n",
    "        y_batch = Y[beg_i:beg_i + batch_size, :]\n",
    "        x_batch = Variable(x_batch)\n",
    "        y_batch = Variable(y_batch)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        # (1) Forward\n",
    "        y_hat = net(x_batch)\n",
    "        # (2) Compute diff\n",
    "        loss = criterion(y_hat, y_batch)\n",
    "        # (3) Compute gradients\n",
    "        loss.backward()\n",
    "        # (4) update weights\n",
    "        opt.step()        \n",
    "        losses.append(loss.data.numpy())\n",
    "    return losses\n",
    "\n",
    "\n",
    "e_losses = []\n",
    "num_epochs = 50\n",
    "for e in range(num_epochs):\n",
    "    e_losses += train_epoch(net, opt, criterion)\n",
    "plt.plot(e_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_t = Variable(torch.randn(1, 8))\n",
    "# print(net(x_t))\n",
    "# x_1_t = Variable(torch.randn(1, 8) + 2)\n",
    "# print(net(x_1_t))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
