{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[537873.75]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.1.11\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas\n",
    "from torch.autograd import Variable # torch 中 Variable 模块\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "xy = np.loadtxt('composite.csv',delimiter=' ', dtype=np.float32) # numpy load data\n",
    "x_data0 = xy[:,0:-1].astype(np.float32) # have to add astype(float)\n",
    "y_data0 = xy[:,[-1]]\n",
    "\n",
    "# print(x_data0)\n",
    "# print(y_data0)\n",
    "\n",
    "x = torch.from_numpy(x_data0) \n",
    "y0 = y_data0\n",
    "\n",
    "y_sort = sorted(y0) \n",
    "median_value = y_sort[data_size//2]\n",
    "print(median_value)\n",
    "y = torch.zeros(data_size,1)\n",
    "\n",
    "for i in range(data_size):\n",
    "    if y0[i] > median_value:\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2,              # subprocesses for loading data\n",
    ")\n",
    "\n",
    "# print(x)\n",
    "# print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc0 = nn.Linear(4, 200)   # hidden layer\n",
    "        self.fc1 = nn.Linear(200, 200)   # hidden layer\n",
    "        self.fc2 = nn.Linear(200, 1)   # output layer\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc0(x))      # activation function for hidden layer\n",
    "        x = F.relu(self.fc1(x))      # activation function for hidden layer\n",
    "        x = self.fc2(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.677\n",
      "[2,   100] loss: 0.620\n",
      "[3,   100] loss: 0.562\n",
      "[4,   100] loss: 0.537\n",
      "[5,   100] loss: 0.512\n",
      "[6,   100] loss: 0.504\n",
      "[7,   100] loss: 0.474\n",
      "[8,   100] loss: 0.460\n",
      "[9,   100] loss: 0.438\n",
      "[10,   100] loss: 0.428\n",
      "[11,   100] loss: 0.409\n",
      "[12,   100] loss: 0.393\n",
      "[13,   100] loss: 0.387\n",
      "[14,   100] loss: 0.371\n",
      "[15,   100] loss: 0.371\n",
      "[16,   100] loss: 0.358\n",
      "[17,   100] loss: 0.346\n",
      "[18,   100] loss: 0.341\n",
      "[19,   100] loss: 0.335\n",
      "[20,   100] loss: 0.325\n",
      "[21,   100] loss: 0.327\n",
      "[22,   100] loss: 0.319\n",
      "[23,   100] loss: 0.312\n",
      "[24,   100] loss: 0.311\n",
      "[25,   100] loss: 0.312\n",
      "[26,   100] loss: 0.297\n",
      "[27,   100] loss: 0.302\n",
      "[28,   100] loss: 0.295\n",
      "[29,   100] loss: 0.297\n",
      "[30,   100] loss: 0.292\n",
      "[31,   100] loss: 0.285\n",
      "[32,   100] loss: 0.281\n",
      "[33,   100] loss: 0.284\n",
      "[34,   100] loss: 0.283\n",
      "[35,   100] loss: 0.283\n",
      "[36,   100] loss: 0.280\n",
      "[37,   100] loss: 0.268\n",
      "[38,   100] loss: 0.269\n",
      "[39,   100] loss: 0.274\n",
      "[40,   100] loss: 0.267\n",
      "[41,   100] loss: 0.266\n",
      "[42,   100] loss: 0.266\n",
      "[43,   100] loss: 0.272\n",
      "[44,   100] loss: 0.261\n",
      "[45,   100] loss: 0.259\n",
      "[46,   100] loss: 0.258\n",
      "[47,   100] loss: 0.261\n",
      "[48,   100] loss: 0.260\n",
      "[49,   100] loss: 0.254\n",
      "[50,   100] loss: 0.257\n",
      "[51,   100] loss: 0.255\n",
      "[52,   100] loss: 0.250\n",
      "[53,   100] loss: 0.253\n",
      "[54,   100] loss: 0.252\n",
      "[55,   100] loss: 0.244\n",
      "[56,   100] loss: 0.245\n",
      "[57,   100] loss: 0.251\n",
      "[58,   100] loss: 0.248\n",
      "[59,   100] loss: 0.239\n",
      "[60,   100] loss: 0.242\n",
      "[61,   100] loss: 0.240\n",
      "[62,   100] loss: 0.238\n",
      "[63,   100] loss: 0.234\n",
      "[64,   100] loss: 0.238\n",
      "[65,   100] loss: 0.239\n",
      "[66,   100] loss: 0.242\n",
      "[67,   100] loss: 0.230\n",
      "[68,   100] loss: 0.233\n",
      "[69,   100] loss: 0.236\n",
      "[70,   100] loss: 0.228\n",
      "[71,   100] loss: 0.229\n",
      "[72,   100] loss: 0.227\n",
      "[73,   100] loss: 0.226\n",
      "[74,   100] loss: 0.229\n",
      "[75,   100] loss: 0.227\n",
      "[76,   100] loss: 0.229\n",
      "[77,   100] loss: 0.231\n",
      "[78,   100] loss: 0.223\n",
      "[79,   100] loss: 0.222\n",
      "[80,   100] loss: 0.220\n",
      "[81,   100] loss: 0.223\n",
      "[82,   100] loss: 0.220\n",
      "[83,   100] loss: 0.219\n",
      "[84,   100] loss: 0.215\n",
      "[85,   100] loss: 0.216\n",
      "[86,   100] loss: 0.208\n",
      "[87,   100] loss: 0.214\n",
      "[88,   100] loss: 0.211\n",
      "[89,   100] loss: 0.213\n",
      "[90,   100] loss: 0.206\n",
      "[91,   100] loss: 0.209\n",
      "[92,   100] loss: 0.215\n",
      "[93,   100] loss: 0.212\n",
      "[94,   100] loss: 0.209\n",
      "[95,   100] loss: 0.213\n",
      "[96,   100] loss: 0.207\n",
      "[97,   100] loss: 0.202\n",
      "[98,   100] loss: 0.201\n",
      "[99,   100] loss: 0.198\n",
      "[100,   100] loss: 0.196\n",
      "[101,   100] loss: 0.200\n",
      "[102,   100] loss: 0.198\n",
      "[103,   100] loss: 0.192\n",
      "[104,   100] loss: 0.191\n",
      "[105,   100] loss: 0.191\n",
      "[106,   100] loss: 0.197\n",
      "[107,   100] loss: 0.189\n",
      "[108,   100] loss: 0.192\n",
      "[109,   100] loss: 0.190\n",
      "[110,   100] loss: 0.185\n",
      "[111,   100] loss: 0.183\n",
      "[112,   100] loss: 0.182\n",
      "[113,   100] loss: 0.186\n",
      "[114,   100] loss: 0.185\n",
      "[115,   100] loss: 0.181\n",
      "[116,   100] loss: 0.180\n",
      "[117,   100] loss: 0.179\n",
      "[118,   100] loss: 0.179\n",
      "[119,   100] loss: 0.180\n",
      "[120,   100] loss: 0.184\n",
      "[121,   100] loss: 0.175\n",
      "[122,   100] loss: 0.175\n",
      "[123,   100] loss: 0.165\n",
      "[124,   100] loss: 0.172\n",
      "[125,   100] loss: 0.164\n",
      "[126,   100] loss: 0.177\n",
      "[127,   100] loss: 0.163\n",
      "[128,   100] loss: 0.167\n",
      "[129,   100] loss: 0.159\n",
      "[130,   100] loss: 0.162\n",
      "[131,   100] loss: 0.160\n",
      "[132,   100] loss: 0.160\n",
      "[133,   100] loss: 0.164\n",
      "[134,   100] loss: 0.156\n",
      "[135,   100] loss: 0.158\n",
      "[136,   100] loss: 0.157\n",
      "[137,   100] loss: 0.161\n",
      "[138,   100] loss: 0.160\n",
      "[139,   100] loss: 0.155\n",
      "[140,   100] loss: 0.153\n",
      "[141,   100] loss: 0.154\n",
      "[142,   100] loss: 0.149\n",
      "[143,   100] loss: 0.152\n",
      "[144,   100] loss: 0.150\n",
      "[145,   100] loss: 0.147\n",
      "[146,   100] loss: 0.146\n",
      "[147,   100] loss: 0.148\n",
      "[148,   100] loss: 0.146\n",
      "[149,   100] loss: 0.148\n",
      "[150,   100] loss: 0.148\n",
      "[151,   100] loss: 0.142\n",
      "[152,   100] loss: 0.143\n",
      "[153,   100] loss: 0.141\n",
      "[154,   100] loss: 0.137\n",
      "[155,   100] loss: 0.141\n",
      "[156,   100] loss: 0.143\n",
      "[157,   100] loss: 0.149\n",
      "[158,   100] loss: 0.142\n",
      "[159,   100] loss: 0.132\n",
      "[160,   100] loss: 0.137\n",
      "[161,   100] loss: 0.135\n",
      "[162,   100] loss: 0.137\n",
      "[163,   100] loss: 0.132\n",
      "[164,   100] loss: 0.130\n",
      "[165,   100] loss: 0.134\n",
      "[166,   100] loss: 0.135\n",
      "[167,   100] loss: 0.130\n",
      "[168,   100] loss: 0.134\n",
      "[169,   100] loss: 0.130\n",
      "[170,   100] loss: 0.125\n",
      "[171,   100] loss: 0.130\n",
      "[172,   100] loss: 0.128\n",
      "[173,   100] loss: 0.132\n",
      "[174,   100] loss: 0.131\n",
      "[175,   100] loss: 0.123\n",
      "[176,   100] loss: 0.126\n",
      "[177,   100] loss: 0.124\n",
      "[178,   100] loss: 0.127\n",
      "[179,   100] loss: 0.123\n",
      "[180,   100] loss: 0.123\n",
      "[181,   100] loss: 0.126\n",
      "[182,   100] loss: 0.125\n",
      "[183,   100] loss: 0.126\n",
      "[184,   100] loss: 0.119\n",
      "[185,   100] loss: 0.119\n",
      "[186,   100] loss: 0.123\n",
      "[187,   100] loss: 0.121\n",
      "[188,   100] loss: 0.127\n",
      "[189,   100] loss: 0.121\n",
      "[190,   100] loss: 0.123\n",
      "[191,   100] loss: 0.124\n",
      "[192,   100] loss: 0.117\n",
      "[193,   100] loss: 0.115\n",
      "[194,   100] loss: 0.119\n",
      "[195,   100] loss: 0.110\n",
      "[196,   100] loss: 0.122\n",
      "[197,   100] loss: 0.123\n",
      "[198,   100] loss: 0.116\n",
      "[199,   100] loss: 0.109\n",
      "[200,   100] loss: 0.115\n",
      "[201,   100] loss: 0.115\n",
      "[202,   100] loss: 0.112\n",
      "[203,   100] loss: 0.110\n",
      "[204,   100] loss: 0.109\n",
      "[205,   100] loss: 0.115\n",
      "[206,   100] loss: 0.112\n",
      "[207,   100] loss: 0.113\n",
      "[208,   100] loss: 0.110\n",
      "[209,   100] loss: 0.114\n",
      "[210,   100] loss: 0.116\n",
      "[211,   100] loss: 0.108\n",
      "[212,   100] loss: 0.107\n",
      "[213,   100] loss: 0.109\n",
      "[214,   100] loss: 0.106\n",
      "[215,   100] loss: 0.110\n",
      "[216,   100] loss: 0.102\n",
      "[217,   100] loss: 0.115\n",
      "[218,   100] loss: 0.112\n",
      "[219,   100] loss: 0.106\n",
      "[220,   100] loss: 0.099\n",
      "[221,   100] loss: 0.103\n",
      "[222,   100] loss: 0.098\n",
      "[223,   100] loss: 0.106\n",
      "[224,   100] loss: 0.113\n",
      "[225,   100] loss: 0.119\n",
      "[226,   100] loss: 0.110\n",
      "[227,   100] loss: 0.104\n",
      "[228,   100] loss: 0.102\n",
      "[229,   100] loss: 0.106\n",
      "[230,   100] loss: 0.101\n",
      "[231,   100] loss: 0.094\n",
      "[232,   100] loss: 0.099\n",
      "[233,   100] loss: 0.098\n",
      "[234,   100] loss: 0.104\n",
      "[235,   100] loss: 0.105\n",
      "[236,   100] loss: 0.100\n",
      "[237,   100] loss: 0.098\n",
      "[238,   100] loss: 0.101\n",
      "[239,   100] loss: 0.101\n",
      "[240,   100] loss: 0.099\n",
      "[241,   100] loss: 0.096\n",
      "[242,   100] loss: 0.100\n",
      "[243,   100] loss: 0.098\n",
      "[244,   100] loss: 0.093\n",
      "[245,   100] loss: 0.096\n",
      "[246,   100] loss: 0.096\n",
      "[247,   100] loss: 0.097\n",
      "[248,   100] loss: 0.093\n",
      "[249,   100] loss: 0.092\n",
      "[250,   100] loss: 0.093\n",
      "[251,   100] loss: 0.099\n",
      "[252,   100] loss: 0.097\n",
      "[253,   100] loss: 0.088\n",
      "[254,   100] loss: 0.107\n",
      "[255,   100] loss: 0.088\n",
      "[256,   100] loss: 0.090\n",
      "[257,   100] loss: 0.091\n",
      "[258,   100] loss: 0.092\n",
      "[259,   100] loss: 0.093\n",
      "[260,   100] loss: 0.097\n",
      "[261,   100] loss: 0.097\n",
      "[262,   100] loss: 0.087\n",
      "[263,   100] loss: 0.087\n",
      "[264,   100] loss: 0.092\n",
      "[265,   100] loss: 0.092\n",
      "[266,   100] loss: 0.092\n",
      "[267,   100] loss: 0.083\n",
      "[268,   100] loss: 0.091\n",
      "[269,   100] loss: 0.093\n",
      "[270,   100] loss: 0.090\n",
      "[271,   100] loss: 0.089\n",
      "[272,   100] loss: 0.087\n",
      "[273,   100] loss: 0.094\n",
      "[274,   100] loss: 0.084\n",
      "[275,   100] loss: 0.084\n",
      "[276,   100] loss: 0.084\n",
      "[277,   100] loss: 0.090\n",
      "[278,   100] loss: 0.083\n",
      "[279,   100] loss: 0.088\n",
      "[280,   100] loss: 0.089\n",
      "[281,   100] loss: 0.079\n",
      "[282,   100] loss: 0.079\n",
      "[283,   100] loss: 0.086\n",
      "[284,   100] loss: 0.085\n",
      "[285,   100] loss: 0.085\n",
      "[286,   100] loss: 0.091\n",
      "[287,   100] loss: 0.096\n",
      "[288,   100] loss: 0.084\n",
      "[289,   100] loss: 0.083\n",
      "[290,   100] loss: 0.076\n",
      "[291,   100] loss: 0.084\n",
      "[292,   100] loss: 0.078\n",
      "[293,   100] loss: 0.083\n",
      "[294,   100] loss: 0.078\n",
      "[295,   100] loss: 0.083\n",
      "[296,   100] loss: 0.081\n",
      "[297,   100] loss: 0.078\n",
      "[298,   100] loss: 0.079\n",
      "[299,   100] loss: 0.073\n",
      "[300,   100] loss: 0.077\n",
      "[301,   100] loss: 0.082\n",
      "[302,   100] loss: 0.081\n",
      "[303,   100] loss: 0.072\n",
      "[304,   100] loss: 0.081\n",
      "[305,   100] loss: 0.081\n",
      "[306,   100] loss: 0.087\n",
      "[307,   100] loss: 0.081\n",
      "[308,   100] loss: 0.077\n",
      "[309,   100] loss: 0.075\n",
      "[310,   100] loss: 0.076\n",
      "[311,   100] loss: 0.075\n",
      "[312,   100] loss: 0.083\n",
      "[313,   100] loss: 0.074\n",
      "[314,   100] loss: 0.078\n",
      "[315,   100] loss: 0.076\n",
      "[316,   100] loss: 0.079\n",
      "[317,   100] loss: 0.070\n",
      "[318,   100] loss: 0.072\n",
      "[319,   100] loss: 0.071\n",
      "[320,   100] loss: 0.083\n",
      "[321,   100] loss: 0.074\n",
      "[322,   100] loss: 0.078\n",
      "[323,   100] loss: 0.077\n",
      "[324,   100] loss: 0.072\n",
      "[325,   100] loss: 0.072\n",
      "[326,   100] loss: 0.085\n",
      "[327,   100] loss: 0.073\n",
      "[328,   100] loss: 0.069\n",
      "[329,   100] loss: 0.064\n",
      "[330,   100] loss: 0.065\n",
      "[331,   100] loss: 0.069\n",
      "[332,   100] loss: 0.088\n",
      "[333,   100] loss: 0.074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[334,   100] loss: 0.072\n",
      "[335,   100] loss: 0.069\n",
      "[336,   100] loss: 0.076\n",
      "[337,   100] loss: 0.067\n",
      "[338,   100] loss: 0.069\n",
      "[339,   100] loss: 0.062\n",
      "[340,   100] loss: 0.069\n",
      "[341,   100] loss: 0.067\n",
      "[342,   100] loss: 0.063\n",
      "[343,   100] loss: 0.068\n",
      "[344,   100] loss: 0.064\n",
      "[345,   100] loss: 0.070\n",
      "[346,   100] loss: 0.073\n",
      "[347,   100] loss: 0.065\n",
      "[348,   100] loss: 0.067\n",
      "[349,   100] loss: 0.059\n",
      "[350,   100] loss: 0.067\n",
      "[351,   100] loss: 0.066\n",
      "[352,   100] loss: 0.070\n",
      "[353,   100] loss: 0.067\n",
      "[354,   100] loss: 0.075\n",
      "[355,   100] loss: 0.068\n",
      "[356,   100] loss: 0.063\n",
      "[357,   100] loss: 0.067\n",
      "[358,   100] loss: 0.059\n",
      "[359,   100] loss: 0.067\n",
      "[360,   100] loss: 0.070\n",
      "[361,   100] loss: 0.060\n",
      "[362,   100] loss: 0.059\n",
      "[363,   100] loss: 0.067\n",
      "[364,   100] loss: 0.068\n",
      "[365,   100] loss: 0.060\n",
      "[366,   100] loss: 0.063\n",
      "[367,   100] loss: 0.072\n",
      "[368,   100] loss: 0.060\n",
      "[369,   100] loss: 0.060\n",
      "[370,   100] loss: 0.066\n",
      "[371,   100] loss: 0.068\n",
      "[372,   100] loss: 0.061\n",
      "[373,   100] loss: 0.066\n",
      "[374,   100] loss: 0.066\n",
      "[375,   100] loss: 0.062\n",
      "[376,   100] loss: 0.058\n",
      "[377,   100] loss: 0.068\n",
      "[378,   100] loss: 0.071\n",
      "[379,   100] loss: 0.060\n",
      "[380,   100] loss: 0.055\n",
      "[381,   100] loss: 0.066\n",
      "[382,   100] loss: 0.056\n",
      "[383,   100] loss: 0.062\n",
      "[384,   100] loss: 0.056\n",
      "[385,   100] loss: 0.055\n",
      "[386,   100] loss: 0.052\n",
      "[387,   100] loss: 0.054\n",
      "[388,   100] loss: 0.064\n",
      "[389,   100] loss: 0.060\n",
      "[390,   100] loss: 0.063\n",
      "[391,   100] loss: 0.072\n",
      "[392,   100] loss: 0.057\n",
      "[393,   100] loss: 0.060\n",
      "[394,   100] loss: 0.064\n",
      "[395,   100] loss: 0.054\n",
      "[396,   100] loss: 0.063\n",
      "[397,   100] loss: 0.059\n",
      "[398,   100] loss: 0.057\n",
      "[399,   100] loss: 0.056\n",
      "[400,   100] loss: 0.063\n",
      "[401,   100] loss: 0.057\n",
      "[402,   100] loss: 0.056\n",
      "[403,   100] loss: 0.056\n",
      "[404,   100] loss: 0.057\n",
      "[405,   100] loss: 0.058\n",
      "[406,   100] loss: 0.054\n",
      "[407,   100] loss: 0.058\n",
      "[408,   100] loss: 0.068\n",
      "[409,   100] loss: 0.066\n",
      "[410,   100] loss: 0.060\n",
      "[411,   100] loss: 0.053\n",
      "[412,   100] loss: 0.055\n",
      "[413,   100] loss: 0.062\n",
      "[414,   100] loss: 0.056\n",
      "[415,   100] loss: 0.056\n",
      "[416,   100] loss: 0.062\n",
      "[417,   100] loss: 0.059\n",
      "[418,   100] loss: 0.060\n",
      "[419,   100] loss: 0.053\n",
      "[420,   100] loss: 0.062\n",
      "[421,   100] loss: 0.062\n",
      "[422,   100] loss: 0.058\n",
      "[423,   100] loss: 0.050\n",
      "[424,   100] loss: 0.052\n",
      "[425,   100] loss: 0.053\n",
      "[426,   100] loss: 0.061\n",
      "[427,   100] loss: 0.052\n",
      "[428,   100] loss: 0.048\n",
      "[429,   100] loss: 0.054\n",
      "[430,   100] loss: 0.051\n",
      "[431,   100] loss: 0.054\n",
      "[432,   100] loss: 0.061\n",
      "[433,   100] loss: 0.054\n",
      "[434,   100] loss: 0.057\n",
      "[435,   100] loss: 0.052\n",
      "[436,   100] loss: 0.062\n",
      "[437,   100] loss: 0.057\n",
      "[438,   100] loss: 0.055\n",
      "[439,   100] loss: 0.048\n",
      "[440,   100] loss: 0.063\n",
      "[441,   100] loss: 0.053\n",
      "[442,   100] loss: 0.046\n",
      "[443,   100] loss: 0.055\n",
      "[444,   100] loss: 0.062\n",
      "[445,   100] loss: 0.054\n",
      "[446,   100] loss: 0.049\n",
      "[447,   100] loss: 0.053\n",
      "[448,   100] loss: 0.054\n",
      "[449,   100] loss: 0.049\n",
      "[450,   100] loss: 0.054\n",
      "[451,   100] loss: 0.057\n",
      "[452,   100] loss: 0.045\n",
      "[453,   100] loss: 0.049\n",
      "[454,   100] loss: 0.046\n",
      "[455,   100] loss: 0.056\n",
      "[456,   100] loss: 0.057\n",
      "[457,   100] loss: 0.047\n",
      "[458,   100] loss: 0.046\n",
      "[459,   100] loss: 0.046\n",
      "[460,   100] loss: 0.046\n",
      "[461,   100] loss: 0.049\n",
      "[462,   100] loss: 0.062\n",
      "[463,   100] loss: 0.046\n",
      "[464,   100] loss: 0.054\n",
      "[465,   100] loss: 0.059\n",
      "[466,   100] loss: 0.059\n",
      "[467,   100] loss: 0.050\n",
      "[468,   100] loss: 0.049\n",
      "[469,   100] loss: 0.050\n",
      "[470,   100] loss: 0.047\n",
      "[471,   100] loss: 0.049\n",
      "[472,   100] loss: 0.052\n",
      "[473,   100] loss: 0.046\n",
      "[474,   100] loss: 0.045\n",
      "[475,   100] loss: 0.047\n",
      "[476,   100] loss: 0.047\n",
      "[477,   100] loss: 0.070\n",
      "[478,   100] loss: 0.052\n",
      "[479,   100] loss: 0.051\n",
      "[480,   100] loss: 0.046\n",
      "[481,   100] loss: 0.050\n",
      "[482,   100] loss: 0.055\n",
      "[483,   100] loss: 0.050\n",
      "[484,   100] loss: 0.041\n",
      "[485,   100] loss: 0.042\n",
      "[486,   100] loss: 0.041\n",
      "[487,   100] loss: 0.043\n",
      "[488,   100] loss: 0.049\n",
      "[489,   100] loss: 0.060\n",
      "[490,   100] loss: 0.043\n",
      "[491,   100] loss: 0.044\n",
      "[492,   100] loss: 0.043\n",
      "[493,   100] loss: 0.047\n",
      "[494,   100] loss: 0.054\n",
      "[495,   100] loss: 0.045\n",
      "[496,   100] loss: 0.053\n",
      "[497,   100] loss: 0.043\n",
      "[498,   100] loss: 0.040\n",
      "[499,   100] loss: 0.044\n",
      "[500,   100] loss: 0.041\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "niter = x.size(0) // BATCH_SIZE\n",
    "for epoch in range(500):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "#         print(i)\n",
    "        # get the inputs \n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimizer\n",
    "#         print(inputs)\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        running_loss +=loss.item()\n",
    "        if i % niter == niter-1: \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch+1, i+1, running_loss/niter))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('done')\n",
    "# print(running_loss)\n",
    "# plt.plot(running_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "测试模型的时候，把tensor 转换成numpy 再用scikit learn 做容易一些\n",
    "\n",
    "if x is tensor  - x.numpy()\n",
    "if x is Variable - x.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.986\n",
      "[[1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "# y_output = net(x).data.numpy()\n",
    "# print(y_output)\n",
    "# print(y)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_output = net(x).data.numpy()\n",
    "y_true = y\n",
    "y_pred = torch.zeros(data_size,1)\n",
    "\n",
    "for i in range(data_size):\n",
    "    if y_output[i]>0.5:\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "x1 = torch.tensor([[2,9,5,1],\n",
    "                  [2,9,5,7],\n",
    "                  [6,9,3,1],\n",
    "                  [2,9,3,1]])\n",
    "y1 = net(x1.float()).data.numpy()\n",
    "print(y1)\n",
    "print(max(y_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation \n",
    "#A scikit-learn compatible neural network library that wraps PyTorch.\n",
    "https://skorch.readthedocs.io/en/latest/?badge=latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
