{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1600.)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.1.11\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas\n",
    "from torch.autograd import Variable # torch 中 Variable 模块\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "data_size = 10000 # n = 10000000 the minimum is 81, so hard to find 64 which is the global minimum\n",
    "x = torch.randint(1,10,(data_size,8))\n",
    "x = x.float()\n",
    "y0 = torch.sum(x,1)**2\n",
    "\n",
    "\n",
    "y_sort = sorted(y0) \n",
    "median_value = y_sort[data_size//2]\n",
    "print(median_value)\n",
    "y = torch.zeros(data_size,1)\n",
    "\n",
    "for i in range(data_size):\n",
    "    if y0[i] > median_value:\n",
    "        y[i] = 1\n",
    "    else:\n",
    "        y[i] = 0\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2,              # subprocesses for loading data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.Linear(8, 100)   # hidden layer\n",
    "        self.fc1 = nn.Linear(100, 1)   # output layer\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,   100] loss: 0.657\n",
      "[2,   100] loss: 0.605\n",
      "[3,   100] loss: 0.569\n",
      "[4,   100] loss: 0.540\n",
      "[5,   100] loss: 0.518\n",
      "[6,   100] loss: 0.503\n",
      "[7,   100] loss: 0.488\n",
      "[8,   100] loss: 0.476\n",
      "[9,   100] loss: 0.464\n",
      "[10,   100] loss: 0.455\n",
      "[11,   100] loss: 0.449\n",
      "[12,   100] loss: 0.442\n",
      "[13,   100] loss: 0.434\n",
      "[14,   100] loss: 0.426\n",
      "[15,   100] loss: 0.421\n",
      "[16,   100] loss: 0.414\n",
      "[17,   100] loss: 0.410\n",
      "[18,   100] loss: 0.402\n",
      "[19,   100] loss: 0.400\n",
      "[20,   100] loss: 0.392\n",
      "[21,   100] loss: 0.386\n",
      "[22,   100] loss: 0.382\n",
      "[23,   100] loss: 0.375\n",
      "[24,   100] loss: 0.368\n",
      "[25,   100] loss: 0.362\n",
      "[26,   100] loss: 0.361\n",
      "[27,   100] loss: 0.354\n",
      "[28,   100] loss: 0.348\n",
      "[29,   100] loss: 0.345\n",
      "[30,   100] loss: 0.341\n",
      "[31,   100] loss: 0.336\n",
      "[32,   100] loss: 0.327\n",
      "[33,   100] loss: 0.322\n",
      "[34,   100] loss: 0.320\n",
      "[35,   100] loss: 0.314\n",
      "[36,   100] loss: 0.308\n",
      "[37,   100] loss: 0.305\n",
      "[38,   100] loss: 0.299\n",
      "[39,   100] loss: 0.294\n",
      "[40,   100] loss: 0.290\n",
      "[41,   100] loss: 0.283\n",
      "[42,   100] loss: 0.280\n",
      "[43,   100] loss: 0.279\n",
      "[44,   100] loss: 0.272\n",
      "[45,   100] loss: 0.266\n",
      "[46,   100] loss: 0.264\n",
      "[47,   100] loss: 0.259\n",
      "[48,   100] loss: 0.257\n",
      "[49,   100] loss: 0.253\n",
      "[50,   100] loss: 0.248\n",
      "[51,   100] loss: 0.248\n",
      "[52,   100] loss: 0.243\n",
      "[53,   100] loss: 0.236\n",
      "[54,   100] loss: 0.234\n",
      "[55,   100] loss: 0.230\n",
      "[56,   100] loss: 0.226\n",
      "[57,   100] loss: 0.223\n",
      "[58,   100] loss: 0.223\n",
      "[59,   100] loss: 0.218\n",
      "[60,   100] loss: 0.215\n",
      "[61,   100] loss: 0.212\n",
      "[62,   100] loss: 0.211\n",
      "[63,   100] loss: 0.208\n",
      "[64,   100] loss: 0.204\n",
      "[65,   100] loss: 0.206\n",
      "[66,   100] loss: 0.200\n",
      "[67,   100] loss: 0.197\n",
      "[68,   100] loss: 0.193\n",
      "[69,   100] loss: 0.192\n",
      "[70,   100] loss: 0.189\n",
      "[71,   100] loss: 0.188\n",
      "[72,   100] loss: 0.187\n",
      "[73,   100] loss: 0.184\n",
      "[74,   100] loss: 0.183\n",
      "[75,   100] loss: 0.182\n",
      "[76,   100] loss: 0.180\n",
      "[77,   100] loss: 0.174\n",
      "[78,   100] loss: 0.173\n",
      "[79,   100] loss: 0.172\n",
      "[80,   100] loss: 0.174\n",
      "[81,   100] loss: 0.168\n",
      "[82,   100] loss: 0.165\n",
      "[83,   100] loss: 0.165\n",
      "[84,   100] loss: 0.164\n",
      "[85,   100] loss: 0.164\n",
      "[86,   100] loss: 0.160\n",
      "[87,   100] loss: 0.158\n",
      "[88,   100] loss: 0.158\n",
      "[89,   100] loss: 0.161\n",
      "[90,   100] loss: 0.153\n",
      "[91,   100] loss: 0.153\n",
      "[92,   100] loss: 0.151\n",
      "[93,   100] loss: 0.153\n",
      "[94,   100] loss: 0.150\n",
      "[95,   100] loss: 0.148\n",
      "[96,   100] loss: 0.150\n",
      "[97,   100] loss: 0.144\n",
      "[98,   100] loss: 0.142\n",
      "[99,   100] loss: 0.141\n",
      "[100,   100] loss: 0.147\n",
      "[101,   100] loss: 0.140\n",
      "[102,   100] loss: 0.138\n",
      "[103,   100] loss: 0.139\n",
      "[104,   100] loss: 0.136\n",
      "[105,   100] loss: 0.135\n",
      "[106,   100] loss: 0.136\n",
      "[107,   100] loss: 0.134\n",
      "[108,   100] loss: 0.132\n",
      "[109,   100] loss: 0.131\n",
      "[110,   100] loss: 0.131\n",
      "[111,   100] loss: 0.132\n",
      "[112,   100] loss: 0.130\n",
      "[113,   100] loss: 0.133\n",
      "[114,   100] loss: 0.129\n",
      "[115,   100] loss: 0.129\n",
      "[116,   100] loss: 0.124\n",
      "[117,   100] loss: 0.128\n",
      "[118,   100] loss: 0.123\n",
      "[119,   100] loss: 0.124\n",
      "[120,   100] loss: 0.127\n",
      "[121,   100] loss: 0.122\n",
      "[122,   100] loss: 0.119\n",
      "[123,   100] loss: 0.119\n",
      "[124,   100] loss: 0.120\n",
      "[125,   100] loss: 0.117\n",
      "[126,   100] loss: 0.119\n",
      "[127,   100] loss: 0.127\n",
      "[128,   100] loss: 0.115\n",
      "[129,   100] loss: 0.118\n",
      "[130,   100] loss: 0.115\n",
      "[131,   100] loss: 0.113\n",
      "[132,   100] loss: 0.112\n",
      "[133,   100] loss: 0.113\n",
      "[134,   100] loss: 0.111\n",
      "[135,   100] loss: 0.112\n",
      "[136,   100] loss: 0.110\n",
      "[137,   100] loss: 0.109\n",
      "[138,   100] loss: 0.108\n",
      "[139,   100] loss: 0.107\n",
      "[140,   100] loss: 0.110\n",
      "[141,   100] loss: 0.106\n",
      "[142,   100] loss: 0.110\n",
      "[143,   100] loss: 0.107\n",
      "[144,   100] loss: 0.110\n",
      "[145,   100] loss: 0.107\n",
      "[146,   100] loss: 0.106\n",
      "[147,   100] loss: 0.104\n",
      "[148,   100] loss: 0.102\n",
      "[149,   100] loss: 0.101\n",
      "[150,   100] loss: 0.103\n",
      "[151,   100] loss: 0.102\n",
      "[152,   100] loss: 0.101\n",
      "[153,   100] loss: 0.101\n",
      "[154,   100] loss: 0.100\n",
      "[155,   100] loss: 0.102\n",
      "[156,   100] loss: 0.101\n",
      "[157,   100] loss: 0.098\n",
      "[158,   100] loss: 0.096\n",
      "[159,   100] loss: 0.098\n",
      "[160,   100] loss: 0.099\n",
      "[161,   100] loss: 0.097\n",
      "[162,   100] loss: 0.099\n",
      "[163,   100] loss: 0.097\n",
      "[164,   100] loss: 0.095\n",
      "[165,   100] loss: 0.098\n",
      "[166,   100] loss: 0.095\n",
      "[167,   100] loss: 0.094\n",
      "[168,   100] loss: 0.093\n",
      "[169,   100] loss: 0.092\n",
      "[170,   100] loss: 0.091\n",
      "[171,   100] loss: 0.091\n",
      "[172,   100] loss: 0.093\n",
      "[173,   100] loss: 0.092\n",
      "[174,   100] loss: 0.093\n",
      "[175,   100] loss: 0.091\n",
      "[176,   100] loss: 0.094\n",
      "[177,   100] loss: 0.090\n",
      "[178,   100] loss: 0.095\n",
      "[179,   100] loss: 0.099\n",
      "[180,   100] loss: 0.089\n",
      "[181,   100] loss: 0.087\n",
      "[182,   100] loss: 0.088\n",
      "[183,   100] loss: 0.086\n",
      "[184,   100] loss: 0.090\n",
      "[185,   100] loss: 0.086\n",
      "[186,   100] loss: 0.087\n",
      "[187,   100] loss: 0.089\n",
      "[188,   100] loss: 0.088\n",
      "[189,   100] loss: 0.085\n",
      "[190,   100] loss: 0.089\n",
      "[191,   100] loss: 0.087\n",
      "[192,   100] loss: 0.085\n",
      "[193,   100] loss: 0.089\n",
      "[194,   100] loss: 0.083\n",
      "[195,   100] loss: 0.087\n",
      "[196,   100] loss: 0.085\n",
      "[197,   100] loss: 0.089\n",
      "[198,   100] loss: 0.084\n",
      "[199,   100] loss: 0.083\n",
      "[200,   100] loss: 0.084\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "niter = x.size(0) // BATCH_SIZE\n",
    "for epoch in range(200):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "#         print(i)\n",
    "        # get the inputs \n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimizer\n",
    "#         print(inputs)\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        running_loss +=loss.item()\n",
    "        if i % niter == niter-1: \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch+1, i+1, running_loss/niter))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('done')\n",
    "# print(running_loss)\n",
    "# plt.plot(running_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "测试模型的时候，把tensor 转换成numpy 再用scikit learn 做容易一些\n",
    "\n",
    "if x is tensor  - x.numpy()\n",
    "if x is Variable - x.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9892\n",
      "[2.8119332e-12]\n"
     ]
    }
   ],
   "source": [
    "# y_output = net(x).data.numpy()\n",
    "# print(y_output)\n",
    "# print(y)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_output = net(x).data.numpy()\n",
    "y_true = y\n",
    "y_pred = torch.zeros(data_size,1)\n",
    "\n",
    "for i in range(data_size):\n",
    "    if y_output[i]>0.5:\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "        \n",
    "# x1 = torch.tensor([[2,1,1,2,2,1,6,2]])\n",
    "# print(x1)\n",
    "# print(x)\n",
    "# net(x1.float()).data.numpy()\n",
    "print(min(y_output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation \n",
    "#A scikit-learn compatible neural network library that wraps PyTorch.\n",
    "https://skorch.readthedocs.io/en/latest/?badge=latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(x.size(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
