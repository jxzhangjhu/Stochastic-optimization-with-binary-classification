{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:95: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:128: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "View more, visit my tutorial page: https://morvanzhou.github.io/tutorials/\n",
    "My Youtube Channel: https://www.youtube.com/user/MorvanZhou\n",
    "Dependencies:\n",
    "torch: 0.1.11\n",
    "\"\"\"\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas\n",
    "from torch.autograd import Variable # torch 中 Variable 模块\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import torch.nn as nn\n",
    "\n",
    "torch.manual_seed(1)    # reproducible\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "\n",
    "# xy = np.loadtxt('sonar.csv',delimiter=' ', dtype=np.float32) # numpy load data\n",
    "dataframe = pandas.read_csv(\"sonar.csv\", header=None)\n",
    "xy = dataframe.values\n",
    "\n",
    "x_data0 = xy[:,0:-1].astype(np.float32) # have to add astype(float)\n",
    "# x_data0 = xy[:,0:-1].astype(float) # have to add astype(float)\n",
    "y_data0 = xy[:,[-1]]\n",
    "\n",
    "x_data = torch.from_numpy(x_data0) \n",
    "\n",
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_data0)\n",
    "y_data1 = encoder.transform(y_data0)\n",
    "\n",
    "y_data = torch.from_numpy(y_data1) \n",
    "y_data = y_data.float()\n",
    "\n",
    "# x = torch.linspace(1, 10, 10)       # this is x data (torch tensor)\n",
    "# y = torch.linspace(10, 1, 10)       # this is y data (torch tensor)\n",
    "# total datasets\n",
    "x = x_data\n",
    "y = y_data\n",
    "\n",
    "test_size = int(x.size(0)*0.1)\n",
    "x_train = x[0:x.size(0) -test_size,: ]\n",
    "y_train = y[0:x.size(0) -test_size]\n",
    "\n",
    "x_test = x[x.size(0) -test_size:x.size(0),:]\n",
    "y_test = y[x.size(0) -test_size:x.size(0)]\n",
    "\n",
    "# print(x_train.size())\n",
    "# print(x_test.size())\n",
    "\n",
    "torch_dataset = Data.TensorDataset(x, y)\n",
    "train_loader = Data.DataLoader(\n",
    "    dataset=torch_dataset,      # torch TensorDataset format\n",
    "    batch_size=BATCH_SIZE,      # mini batch size\n",
    "    shuffle=True,               # random shuffle for training\n",
    "    num_workers=2,              # subprocesses for loading data\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.hidden = nn.Linear(60, 100)   # hidden layer\n",
    "        self.fc1 = nn.Linear(100, 1)   # output layer\n",
    "        self.out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.hidden(x))      # activation function for hidden layer\n",
    "        x = self.fc1(x)\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "    \n",
    "net = Net()\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum = 0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,    26] loss: 0.692\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/7jz/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:2016: UserWarning: Using a target size (torch.Size([8])) that is different to the input size (torch.Size([8, 1])) is deprecated. Please ensure they have the same size.\n",
      "  \"Please ensure they have the same size.\".format(target.size(), input.size()))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2,    26] loss: 0.690\n",
      "[3,    26] loss: 0.688\n",
      "[4,    26] loss: 0.686\n",
      "[5,    26] loss: 0.685\n",
      "[6,    26] loss: 0.684\n",
      "[7,    26] loss: 0.682\n",
      "[8,    26] loss: 0.681\n",
      "[9,    26] loss: 0.679\n",
      "[10,    26] loss: 0.678\n",
      "[11,    26] loss: 0.677\n",
      "[12,    26] loss: 0.675\n",
      "[13,    26] loss: 0.674\n",
      "[14,    26] loss: 0.673\n",
      "[15,    26] loss: 0.671\n",
      "[16,    26] loss: 0.669\n",
      "[17,    26] loss: 0.668\n",
      "[18,    26] loss: 0.666\n",
      "[19,    26] loss: 0.665\n",
      "[20,    26] loss: 0.663\n",
      "[21,    26] loss: 0.662\n",
      "[22,    26] loss: 0.661\n",
      "[23,    26] loss: 0.659\n",
      "[24,    26] loss: 0.657\n",
      "[25,    26] loss: 0.655\n",
      "[26,    26] loss: 0.654\n",
      "[27,    26] loss: 0.652\n",
      "[28,    26] loss: 0.650\n",
      "[29,    26] loss: 0.648\n",
      "[30,    26] loss: 0.646\n",
      "[31,    26] loss: 0.645\n",
      "[32,    26] loss: 0.642\n",
      "[33,    26] loss: 0.640\n",
      "[34,    26] loss: 0.638\n",
      "[35,    26] loss: 0.636\n",
      "[36,    26] loss: 0.634\n",
      "[37,    26] loss: 0.632\n",
      "[38,    26] loss: 0.630\n",
      "[39,    26] loss: 0.627\n",
      "[40,    26] loss: 0.627\n",
      "[41,    26] loss: 0.623\n",
      "[42,    26] loss: 0.621\n",
      "[43,    26] loss: 0.618\n",
      "[44,    26] loss: 0.615\n",
      "[45,    26] loss: 0.613\n",
      "[46,    26] loss: 0.610\n",
      "[47,    26] loss: 0.609\n",
      "[48,    26] loss: 0.606\n",
      "[49,    26] loss: 0.603\n",
      "[50,    26] loss: 0.601\n",
      "[51,    26] loss: 0.599\n",
      "[52,    26] loss: 0.595\n",
      "[53,    26] loss: 0.594\n",
      "[54,    26] loss: 0.590\n",
      "[55,    26] loss: 0.588\n",
      "[56,    26] loss: 0.586\n",
      "[57,    26] loss: 0.583\n",
      "[58,    26] loss: 0.581\n",
      "[59,    26] loss: 0.578\n",
      "[60,    26] loss: 0.575\n",
      "[61,    26] loss: 0.573\n",
      "[62,    26] loss: 0.570\n",
      "[63,    26] loss: 0.568\n",
      "[64,    26] loss: 0.564\n",
      "[65,    26] loss: 0.562\n",
      "[66,    26] loss: 0.561\n",
      "[67,    26] loss: 0.561\n",
      "[68,    26] loss: 0.554\n",
      "[69,    26] loss: 0.552\n",
      "[70,    26] loss: 0.549\n",
      "[71,    26] loss: 0.547\n",
      "[72,    26] loss: 0.544\n",
      "[73,    26] loss: 0.543\n",
      "[74,    26] loss: 0.540\n",
      "[75,    26] loss: 0.537\n",
      "[76,    26] loss: 0.534\n",
      "[77,    26] loss: 0.532\n",
      "[78,    26] loss: 0.531\n",
      "[79,    26] loss: 0.527\n",
      "[80,    26] loss: 0.525\n",
      "[81,    26] loss: 0.522\n",
      "[82,    26] loss: 0.520\n",
      "[83,    26] loss: 0.518\n",
      "[84,    26] loss: 0.516\n",
      "[85,    26] loss: 0.513\n",
      "[86,    26] loss: 0.512\n",
      "[87,    26] loss: 0.509\n",
      "[88,    26] loss: 0.507\n",
      "[89,    26] loss: 0.505\n",
      "[90,    26] loss: 0.503\n",
      "[91,    26] loss: 0.500\n",
      "[92,    26] loss: 0.499\n",
      "[93,    26] loss: 0.497\n",
      "[94,    26] loss: 0.501\n",
      "[95,    26] loss: 0.491\n",
      "[96,    26] loss: 0.492\n",
      "[97,    26] loss: 0.491\n",
      "[98,    26] loss: 0.487\n",
      "[99,    26] loss: 0.487\n",
      "[100,    26] loss: 0.485\n",
      "[101,    26] loss: 0.482\n",
      "[102,    26] loss: 0.480\n",
      "[103,    26] loss: 0.478\n",
      "[104,    26] loss: 0.476\n",
      "[105,    26] loss: 0.475\n",
      "[106,    26] loss: 0.474\n",
      "[107,    26] loss: 0.472\n",
      "[108,    26] loss: 0.471\n",
      "[109,    26] loss: 0.468\n",
      "[110,    26] loss: 0.469\n",
      "[111,    26] loss: 0.468\n",
      "[112,    26] loss: 0.465\n",
      "[113,    26] loss: 0.465\n",
      "[114,    26] loss: 0.461\n",
      "[115,    26] loss: 0.461\n",
      "[116,    26] loss: 0.461\n",
      "[117,    26] loss: 0.458\n",
      "[118,    26] loss: 0.457\n",
      "[119,    26] loss: 0.454\n",
      "[120,    26] loss: 0.455\n",
      "[121,    26] loss: 0.459\n",
      "[122,    26] loss: 0.453\n",
      "[123,    26] loss: 0.450\n",
      "[124,    26] loss: 0.449\n",
      "[125,    26] loss: 0.448\n",
      "[126,    26] loss: 0.447\n",
      "[127,    26] loss: 0.445\n",
      "[128,    26] loss: 0.445\n",
      "[129,    26] loss: 0.444\n",
      "[130,    26] loss: 0.444\n",
      "[131,    26] loss: 0.441\n",
      "[132,    26] loss: 0.441\n",
      "[133,    26] loss: 0.438\n",
      "[134,    26] loss: 0.437\n",
      "[135,    26] loss: 0.436\n",
      "[136,    26] loss: 0.436\n",
      "[137,    26] loss: 0.438\n",
      "[138,    26] loss: 0.434\n",
      "[139,    26] loss: 0.432\n",
      "[140,    26] loss: 0.433\n",
      "[141,    26] loss: 0.432\n",
      "[142,    26] loss: 0.429\n",
      "[143,    26] loss: 0.430\n",
      "[144,    26] loss: 0.427\n",
      "[145,    26] loss: 0.427\n",
      "[146,    26] loss: 0.426\n",
      "[147,    26] loss: 0.425\n",
      "[148,    26] loss: 0.424\n",
      "[149,    26] loss: 0.424\n",
      "[150,    26] loss: 0.423\n",
      "[151,    26] loss: 0.423\n",
      "[152,    26] loss: 0.420\n",
      "[153,    26] loss: 0.420\n",
      "[154,    26] loss: 0.422\n",
      "[155,    26] loss: 0.422\n",
      "[156,    26] loss: 0.419\n",
      "[157,    26] loss: 0.418\n",
      "[158,    26] loss: 0.418\n",
      "[159,    26] loss: 0.417\n",
      "[160,    26] loss: 0.415\n",
      "[161,    26] loss: 0.413\n",
      "[162,    26] loss: 0.415\n",
      "[163,    26] loss: 0.412\n",
      "[164,    26] loss: 0.413\n",
      "[165,    26] loss: 0.410\n",
      "[166,    26] loss: 0.409\n",
      "[167,    26] loss: 0.409\n",
      "[168,    26] loss: 0.408\n",
      "[169,    26] loss: 0.408\n",
      "[170,    26] loss: 0.410\n",
      "[171,    26] loss: 0.410\n",
      "[172,    26] loss: 0.405\n",
      "[173,    26] loss: 0.408\n",
      "[174,    26] loss: 0.404\n",
      "[175,    26] loss: 0.404\n",
      "[176,    26] loss: 0.403\n",
      "[177,    26] loss: 0.402\n",
      "[178,    26] loss: 0.404\n",
      "[179,    26] loss: 0.402\n",
      "[180,    26] loss: 0.406\n",
      "[181,    26] loss: 0.399\n",
      "[182,    26] loss: 0.405\n",
      "[183,    26] loss: 0.400\n",
      "[184,    26] loss: 0.401\n",
      "[185,    26] loss: 0.402\n",
      "[186,    26] loss: 0.399\n",
      "[187,    26] loss: 0.400\n",
      "[188,    26] loss: 0.397\n",
      "[189,    26] loss: 0.396\n",
      "[190,    26] loss: 0.398\n",
      "[191,    26] loss: 0.397\n",
      "[192,    26] loss: 0.393\n",
      "[193,    26] loss: 0.393\n",
      "[194,    26] loss: 0.392\n",
      "[195,    26] loss: 0.393\n",
      "[196,    26] loss: 0.392\n",
      "[197,    26] loss: 0.394\n",
      "[198,    26] loss: 0.391\n",
      "[199,    26] loss: 0.390\n",
      "[200,    26] loss: 0.390\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "niter = x.size(0) // BATCH_SIZE\n",
    "for epoch in range(200):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader,0):\n",
    "#         print(i)\n",
    "        # get the inputs \n",
    "        inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimizer\n",
    "#         print(inputs)\n",
    "        outputs = net(inputs)\n",
    "#         print(outputs)\n",
    "#         print(labels)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        #print statistics\n",
    "        running_loss +=loss.item()\n",
    "        if i % niter == niter-1: \n",
    "            print('[%d, %5d] loss: %.3f' %(epoch+1, i+1, running_loss/niter))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('done')\n",
    "# print(running_loss)\n",
    "# plt.plot(running_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing\n",
    "\n",
    "测试模型的时候，把tensor 转换成numpy 再用scikit learn 做容易一些\n",
    "\n",
    "if x is tensor  - x.numpy()\n",
    "if x is Variable - x.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8317307692307693\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_output = net(x).data.numpy()\n",
    "y_true = y_data1\n",
    "\n",
    "for i in range(x.size(0)):\n",
    "    if y_output[i]>0.5:\n",
    "        y_pred[i] = 1\n",
    "    else:\n",
    "        y_pred[i] = 0\n",
    "\n",
    "print(accuracy_score(y_true, y_pred))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cross-validation \n",
    "#A scikit-learn compatible neural network library that wraps PyTorch.\n",
    "https://skorch.readthedocs.io/en/latest/?badge=latest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
